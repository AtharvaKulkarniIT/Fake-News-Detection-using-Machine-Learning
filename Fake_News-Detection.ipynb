{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMTuzwrbRlyDZ/dTYhb11lZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashkulkarni45/Fake-News-Detection-using-Machine-Learning/blob/main/Fake_News_Detection_EDAI_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSvDarkj5Gz-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "\n",
        "import plotly.express as px\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Dataset"
      ],
      "metadata": {
        "id": "JlHYn2bSAZHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_true = pd.read_csv(\"/content/True.csv\")\n",
        "df_fake = pd.read_csv(\"/content/Fake.csv\")"
      ],
      "metadata": {
        "id": "QEJY0uPxAV8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up a target and merging both datasets"
      ],
      "metadata": {
        "id": "Bz--Y-w8ApoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_true['target'] = 1\n",
        "df_fake['target'] = 0\n",
        "df = pd.concat([df_true, df_fake]).reset_index(drop = True)\n",
        "df['original'] = df['title'] + ' ' + df['text']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "fQAU7H4aAl4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the number of null values"
      ],
      "metadata": {
        "id": "MGWwPL2xA4g4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "mMyLUkXvA6zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Data cleaning"
      ],
      "metadata": {
        "id": "5-yq9hPDA9hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stop_words:\n",
        "            result.append(token)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "GiQml5SDA_Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.subject=df.subject.replace({'politics':'PoliticsNews','politicsNews':'PoliticsNews'})"
      ],
      "metadata": {
        "id": "PDci4K5lBDvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY DATA ANALYSIS - EDA"
      ],
      "metadata": {
        "id": "OPlpOmioBGWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Distribution of true and fake news"
      ],
      "metadata": {
        "id": "p_2Kr1DeBKPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_tf_df=df.groupby('target').apply(lambda x:x['title'].count()).reset_index(name='Counts')\n",
        "sub_tf_df.target.replace({0:'False',1:'True'},inplace=True)\n",
        "fig = px.bar(sub_tf_df, x=\"target\", y=\"Counts\",\n",
        "             color='Counts', barmode='group',\n",
        "             height=400)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "XoZZGj0NBJBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What issues have been most covered in the news?"
      ],
      "metadata": {
        "id": "UlIdb3D3BaBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_check=df.groupby('subject').apply(lambda x:x['title'].count()).reset_index(name='Counts')\n",
        "fig=px.bar(sub_check,x='subject',y='Counts',color='Counts',title='Count of News Articles by Subject')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mlGj66-TBYbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Word Cloud"
      ],
      "metadata": {
        "id": "32vOUOSsBi1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_title'] = df['title'].apply(preprocess)\n",
        "df['clean_title'][0]\n",
        "df['clean_joined_title']=df['clean_title'].apply(lambda x:\" \".join(x))\n",
        "plt.figure(figsize = (20,20))\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = stop_words).generate(\" \".join(df[df.target == 1].clean_joined_title))\n",
        "plt.imshow(wc, interpolation = 'bilinear')"
      ],
      "metadata": {
        "id": "-FJZDCaNBkrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Maximum count of words in a title"
      ],
      "metadata": {
        "id": "3KAS5F8DCAvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "maxlen = -1\n",
        "for doc in df.clean_joined_title:\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    if(maxlen<len(tokens)):\n",
        "        maxlen = len(tokens)\n",
        "print(\"The maximum number of words in a title is =\", maxlen)\n",
        "fig = px.histogram(x = [len(nltk.word_tokenize(x)) for x in df.clean_joined_title], nbins = 50)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "KFlWKVLTCMUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "_a0smthOEkI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "mlSVtlyKDxLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def wordopt(text):\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub(\"\\\\W\",\" \",text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "df[\"text\"] = df[\"text\"].apply(wordopt)"
      ],
      "metadata": {
        "id": "5NX-vRKsDzIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "oAFNnRKyEaL3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train test split"
      ],
      "metadata": {
        "id": "IWcCVOr4EdLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df[\"text\"]\n",
        "y = df[\"target\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
      ],
      "metadata": {
        "id": "9-FY9nOoEfQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "xNaAXuQPEuIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "vectorization = TfidfVectorizer()\n",
        "xv_train = vectorization.fit_transform(x_train)\n",
        "xv_test = vectorization.transform(x_test)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(xv_train,y_train)\n",
        "\n",
        "pred_lr=LR.predict(xv_test)\n",
        "LR.score(xv_test, y_test)\n",
        "\n",
        "print(classification_report(y_test, pred_lr))\n",
        "\n",
        "confusion_mat = confusion_matrix(y_test, pred_lr)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Logistic Regression')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iirSBSUYEwnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Classifier"
      ],
      "metadata": {
        "id": "rBykfh8lFrz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "DT = DecisionTreeClassifier()\n",
        "DT.fit(xv_train, y_train)\n",
        "\n",
        "pred_dt = DT.predict(xv_test)\n",
        "accuracy = DT.score(xv_test, y_test) * 100\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "print(classification_report(y_test, pred_dt))\n",
        "\n",
        "confusion_mat = confusion_matrix(y_test, pred_dt)\n",
        "# Create a heatmap for the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Decision Tree Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kOIfW_1SFu7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "-sOmPSCkF8EB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "GBC = GradientBoostingClassifier(random_state=0)\n",
        "GBC.fit(xv_train, y_train)\n",
        "\n",
        "pred_gbc = GBC.predict(xv_test)\n",
        "accuracy = GBC.score(xv_test, y_test) * 100\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "print(classification_report(y_test, pred_gbc))\n",
        "\n",
        "confusion_mat = confusion_matrix(y_test, pred_gbc)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Gradient Boosting Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3FdW0xVEF-qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Classfier"
      ],
      "metadata": {
        "id": "UjTHRAmAGABX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RFC = RandomForestClassifier(random_state=0)\n",
        "RFC.fit(xv_train, y_train)\n",
        "\n",
        "pred_rfc = RFC.predict(xv_test)\n",
        "accuracy = RFC.score(xv_test, y_test) * 100\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "print(classification_report(y_test, pred_rfc))\n",
        "\n",
        "confusion_mat = confusion_matrix(y_test, pred_rfc)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Random Forest Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qhU_QoiFGB-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking Manual Inputs"
      ],
      "metadata": {
        "id": "seUsE8QXGLMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output_lable(n):\n",
        "    if n == 0:\n",
        "        return \"Fake News\"\n",
        "    elif n == 1:\n",
        "        return \"Not A Fake News\"\n",
        "\n",
        "def manual_testing(news):\n",
        "    testing_news = {\"text\": [news]}\n",
        "    new_def_test = pd.DataFrame(testing_news)\n",
        "    new_def_test[\"text\"] = new_def_test[\"text\"].apply(wordopt)\n",
        "    new_x_test = new_def_test[\"text\"]\n",
        "    new_xv_test = vectorization.transform(new_x_test)\n",
        "    pred_LR = LR.predict(new_xv_test)\n",
        "    pred_DT = DT.predict(new_xv_test)\n",
        "    pred_GBC = GBC.predict(new_xv_test)\n",
        "    pred_RFC = RFC.predict(new_xv_test)\n",
        "\n",
        "    return print(\"\\n\\nLR Prediction: {} \\nDT Prediction: {} \\nGBC Prediction: {} \\nRFC Prediction: {}\".format(output_lable(pred_LR[0]),                                                                                                       output_lable(pred_DT[0]),\n",
        "                                                                                                              output_lable(pred_GBC[0]),\n",
        "                                                                                                              output_lable(pred_RFC[0])))\n",
        "\n"
      ],
      "metadata": {
        "id": "ZlI1TZGoGKkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hindi to English news translation"
      ],
      "metadata": {
        "id": "w_0QjJ9pINP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall googletrans\n",
        "!pip3 install googletrans==3.1.0a0\n",
        "from googletrans import Translator, constants\n",
        "from pprint import pprint\n",
        "\n",
        "def translation (text):\n",
        "\n",
        " translator = Translator()\n",
        "\n",
        " translation = translator.translate(text, dest=\"en\")\n",
        " print(translation.text)"
      ],
      "metadata": {
        "id": "e4nCYserIRKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving user a menu"
      ],
      "metadata": {
        "id": "6an-IFDAJ_ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fake News Detection\n",
        "\n",
        "text = '\\u0928\\u0908 \\u0926\\u093F\\u0932\\u094D\\u0932\\u0940: \\u0905\\u092E\\u0947\\u0930\\u093F\\u0915\\u093E \\u0914\\u0930 \\u091A\\u0940\\u0928 \\u0915\\u0947 \\u092C\\u0940\\u091A \\u092A\\u0930\\u092E\\u093E\\u0923\\u0941 \\u0939\\u0925\\u093F\\u092F\\u093E\\u0930 \\u0928\\u093F\\u092F\\u0902\\u0924\\u094D\\u0930\\u0923 \\u0935\\u093E\\u0930\\u094D\\u0924\\u093E (US China On Nuclear Arms Control) \\u092A\\u0930 \\u0938\\u0939\\u092E\\u0924\\u093F \\u092C\\u0928 \\u0917\\u0908 \\u0939\\u0948. \\u0926\\u094B\\u0928\\u094B\\u0902 \\u0915\\u0947 \\u092C\\u0940\\u091A \\u092F\\u0947 \\u092C\\u093E\\u0924\\u091A\\u0940\\u0924 \\u0905\\u0917\\u0932\\u0947 \\u0939\\u092B\\u094D\\u0924\\u0947 \\u0939\\u094B\\u0917\\u0940. \\u0930\\u0949\\u092F\\u091F\\u0930\\u094D\\u0938 \\u0915\\u0940 \\u0916\\u092C\\u0930 \\u0915\\u0947 \\u092E\\u0941\\u0924\\u093E\\u092C\\u093F\\u0915 \\u092F\\u0947 \\u091C\\u093E\\u0928\\u0915\\u093E\\u0930\\u0940 \\u0935\\u0949\\u0932 \\u0938\\u094D\\u091F\\u094D\\u0930\\u0940\\u091F \\u091C\\u0930\\u094D\\u0928\\u0932 \\u0928\\u0947 \\u092C\\u0941\\u0927\\u0935\\u093E\\u0930 \\u0915\\u094B \\u0926\\u0940. \\u0909\\u0928\\u094D\\u0939\\u094B\\u0902\\u0928\\u0947 \\u092C\\u0924\\u093E\\u092F\\u093E \\u0915\\u093F \\u091A\\u0940\\u0928 \\u0928\\u0947 \\u0905\\u092E\\u0947\\u0930\\u093F\\u0915\\u093E \\u0915\\u0947 \\u0938\\u093E\\u0925 \\u092A\\u0930\\u092E\\u093E\\u0923\\u0941 \\u0939\\u0925\\u093F\\u092F\\u093E\\u0930 \\u0928\\u093F\\u092F\\u0902\\u0924\\u094D\\u0930\\u0923 \\u0935\\u093E\\u0930\\u094D\\u0924\\u093E \\u0906\\u092F\\u094B\\u091C\\u093F\\u0924 \\u0915\\u0930\\u0928\\u0947 \\u092A\\u0930 \\u0938\\u0939\\u092E\\u0924\\u093F \\u091C\\u0924\\u093E \\u0926\\u0940 \\u0939\\u0948. \\u0913\\u092C\\u093E\\u092E\\u093E \\u0938\\u0930\\u0915\\u093E\\u0930 \\u0915\\u0947 \\u0938\\u0924\\u094D\\u0924\\u093E \\u0938\\u0947 \\u091C\\u093E\\u0928\\u0947 \\u0915\\u0947 \\u092C\\u093E\\u0926 \\u092A\\u0939\\u0932\\u0940 \\u092C\\u093E\\u0930 \\u091A\\u0940\\u0928 \\u0914\\u0930 \\u0905\\u092E\\u0947\\u0930\\u093F\\u0915\\u093E \\u0915\\u0947 \\u092C\\u0940\\u091A \\u092A\\u0930\\u092E\\u093E\\u0923\\u0941 \\u0939\\u0925\\u093F\\u092F\\u093E\\u0930 \\u0928\\u093F\\u092F\\u0902\\u0924\\u094D\\u0930\\u0923 \\u092A\\u0930 \\u092C\\u093E\\u0924\\u091A\\u0940\\u0924 \\u0939\\u094B\\u0917\\u0940. \\u0932\\u0947\\u0915\\u093F\\u0928 \\u0926\\u094B\\u0928\\u094B\\u0902 \\u0915\\u0947 \\u092C\\u0940\\u091A \\u092A\\u0930\\u092E\\u093E\\u0923\\u0941 \\u0939\\u0925\\u093F\\u092F\\u093E\\u0930\\u094B\\u0902 \\u0915\\u094B \\u0938\\u0940\\u092E\\u093F\\u0924 \\u0915\\u0930\\u0928\\u0947 \\u092A\\u0930 \\u0938\\u0939\\u092E\\u0924\\u093F \\u092C\\u0928\\u0947\\u0917\\u0940' #@param {type:\"string\"}\n",
        "dropdown = 'Hindi' #@param [\"English\",\"Hindi\"]\n",
        "\n",
        "if dropdown == 'English':\n",
        "  manual_testing(text)\n",
        "else:\n",
        "  new_text = str(translation(text))\n",
        "  print(new_text)\n",
        "  manual_testing(new_text)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gNdqPP93KKtA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
